   Compiling bindgen v0.72.1
   Compiling llama-cpp-sys-2 v0.1.132
   Compiling llama-cpp-2 v0.1.132
   Compiling localm v0.1.0 (C:\Users\crist\Desktop\LocaLM)
error[E0277]: `NonNull<llama_cpp_sys_2::llama_context>` cannot be sent between threads safely
   --> src\inference\engine.rs:252:23
    |
252 |           thread::spawn(move || {
    |           ------------- ^------
    |           |             |
    |  _________|_____________within this `{closure@src\inference\engine.rs:252:23: 252:30}`
    | |         |
    | |         required by a bound introduced by this call
253 | |             let result = run_inference(
254 | |                 &mut ctx,
255 | |                 &model_clone,
...   |
265 | |         });
    | |_________^ `NonNull<llama_cpp_sys_2::llama_context>` cannot be sent between threads safely
    |
    = help: within `{closure@src\inference\engine.rs:252:23: 252:30}`, the trait `Send` is not implemented for `NonNull<llama_cpp_sys_2::llama_context>`
note: required because it appears within the type `LlamaContext<'_>`
   --> C:\Users\crist\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\llama-cpp-2-0.1.132\src\context.rs:25:12
    |
25  | pub struct LlamaContext<'a> {
    |            ^^^^^^^^^^^^
note: required because it's used within this closure
   --> src\inference\engine.rs:252:23
    |
252 |         thread::spawn(move || {
    |                       ^^^^^^^
note: required by a bound in `std::thread::spawn`
   --> C:\Users\crist\.rustup\toolchains\1.87.0-x86_64-pc-windows-msvc\lib/rustlib/src/rust\library\std\src\thread\mod.rs:726:8
    |
723 | pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    |        ----- required by a bound in this function
...
726 |     F: Send + 'static,
    |        ^^^^ required by this bound in `spawn`

For more information about this error, try `rustc --explain E0277`.
error: could not compile `localm` (lib) due to 1 previous error
